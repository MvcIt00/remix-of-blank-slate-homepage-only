# META-CONSULENZA: Ottimizzazione Regole Anti-Approssimazione per AI v4.0

**Data**: 26 Dicembre 2025  
**Versione**: 4.0  
**Stato**: Documento Finale

---

## EXECUTIVE SUMMARY

Questo documento presenta un'analisi completa e ottimizzazione delle Regole Anti-Approssimazione v3.0, strutturata in due task sequenziali come richiesto:

- **TASK 1**: Analisi critica delle regole ¬ß1-12, identificazione di punti ciechi, proposta di tranelli aggiuntivi, ottimizzazioni linguistiche e integrazione di tecniche avanzate
- **TASK 2**: Ricerca web aggiornata (2024-2025) su tecniche di prompt engineering innovative, con valutazione di applicabilit√† e proposte integrative

La ricerca parallela ha identificato **16 nuove tecniche** non presenti nelle Conoscenze Consolidate, con fonti verificabili e metriche di impatto documentate.

---

# TASK 1: ANALISI E OTTIMIZZAZIONE REGOLE v3.0

---

## 1. PUNTI CIECHI IDENTIFICATI

### PUNTO CIECO #1: Assenza di Verifica Temporale delle Dipendenze

**SINTOMO**: L'AI pu√≤ verificare che una colonna esista in un file, ma non verifica se quel file √® stato modificato dopo l'ultima lettura di file dipendenti. Esempio: `types.ts` viene aggiornato, ma il componente React che lo importa usa ancora la vecchia struttura in memoria.

**TRANELLO PROPOSTO**: 
```yaml
DEPENDENCY_TIMESTAMP_CHECK:
  command: "VERIFY dependency freshness before any modification"
  mechanism:
    - For each file F referenced in current turn
    - Check last_modified_timestamp of F
    - Check last_modified_timestamp of all files that IMPORT F
    - If importer.timestamp < F.timestamp ‚Üí STALE_DEPENDENCY_WARNING
  format: |
    DEPENDENCY FRESHNESS:
    ‚îú‚îÄ types.ts: modified T+45
    ‚îú‚îÄ usePreventiviNoleggio.ts: imports types.ts, last read T+12 ‚Üí STALE
    ‚îî‚îÄ ACTION: Re-read usePreventiviNoleggio.ts before proceeding
```

---

### PUNTO CIECO #2: Mancanza di Verifica Semantica delle Negazioni

**SINTOMO**: L'AI pu√≤ dichiarare negazioni che sono tecnicamente vere ma semanticamente irrilevanti. Esempio: "La colonna `email` NON esiste nella tabella `Logs`" ‚Äî vero, ma irrilevante se il task riguarda `Anagrafiche`.

**TRANELLO PROPOSTO**:
```yaml
SEMANTIC_NEGATION_RELEVANCE:
  command: "VALIDATE that each negation is semantically relevant to the current task"
  mechanism:
    - For each negation N declared
    - Verify N relates to the same functional domain as the affirmation
    - Require explicit justification of WHY this negation matters
  format: |
    NEGAZIONE VERIFICATA:
    ‚ùå [cosa NON esiste] - [come verificato]
    üìé RILEVANZA: [perch√© questa negazione √® importante per il task corrente]
  failure_example: |
    ‚ùå SBAGLIATO: "email NON esiste in Logs" (irrilevante per task su Anagrafiche)
    ‚úÖ CORRETTO: "email NON esiste in prev_noleggi (solo in View aggregata)" 
                 ‚Üí RILEVANZA: "Evita JOIN errato se si cerca email direttamente"
```

---

### PUNTO CIECO #3: Assenza di Controllo sulla Propagazione di Default Values

**SINTOMO**: L'AI pu√≤ introdurre valori di default che propagano silenziosamente attraverso il sistema, causando comportamenti inattesi. Esempio: `owner_ragione_sociale ?? 'N/A'` pu√≤ propagarsi in PDF, email, dashboard senza che l'AI verifichi tutti i punti di consumo.

**TRANELLO PROPOSTO**:
```yaml
DEFAULT_VALUE_PROPAGATION_AUDIT:
  command: "TRACE all consumption points of any default value introduced"
  mechanism:
    - When introducing a default/fallback value
    - Execute grep_search for the variable name
    - Map all files that consume this variable
    - Verify each consumption point handles the default appropriately
  format: |
    DEFAULT VALUE AUDIT:
    ‚îú‚îÄ Variable: owner_ragione_sociale
    ‚îú‚îÄ Default introduced: 'N/A' @ PreventiviNoleggio.tsx:156
    ‚îú‚îÄ Consumption points:
    ‚îÇ   ‚îú‚îÄ LetterheadPDF.tsx:89 ‚Üí Displays in header ‚ö†Ô∏è VERIFY FORMATTING
    ‚îÇ   ‚îú‚îÄ EmailTemplate.tsx:34 ‚Üí Used in greeting ‚Üí ‚ùå 'N/A' inappropriate
    ‚îÇ   ‚îî‚îÄ Dashboard.tsx:201 ‚Üí Aggregation count ‚Üí ‚úÖ OK (filtered out)
    ‚îî‚îÄ ACTION REQUIRED: Fix EmailTemplate.tsx greeting logic
```

---

### PUNTO CIECO #4: Mancanza di Verifica di Idempotenza delle Operazioni

**SINTOMO**: L'AI pu√≤ proporre modifiche che, se eseguite pi√π volte, producono risultati diversi o corrompono i dati. Esempio: `UPDATE SET counter = counter + 1` eseguito due volte raddoppia erroneamente il contatore.

**TRANELLO PROPOSTO**:
```yaml
IDEMPOTENCY_CHECK:
  command: "VERIFY that proposed operation is idempotent OR explicitly flag non-idempotent operations"
  mechanism:
    - For each SQL/modification proposed
    - Ask: "If executed twice, what happens?"
    - If result differs ‚Üí FLAG as NON-IDEMPOTENT
    - Require explicit safeguard (e.g., WHERE clause, transaction)
  format: |
    IDEMPOTENCY ANALYSIS:
    ‚îú‚îÄ Operation: UPDATE Anagrafiche SET ragione_sociale = 'Mvc Toscana Carrelli'
    ‚îú‚îÄ Idempotent: ‚úÖ YES (same result if executed multiple times)
    
    ‚îú‚îÄ Operation: UPDATE Anagrafiche SET counter = counter + 1
    ‚îú‚îÄ Idempotent: ‚ùå NO (increments each execution)
    ‚îî‚îÄ SAFEGUARD REQUIRED: Add WHERE last_updated < NOW() - INTERVAL 1 MINUTE
```

---

## 2. TRANELLI PROPOSTI

### TRANELLO #12: Verifica di Coerenza Tipologica Cross-Layer

**PUNTO CIECO CONTRASTATO**: L'AI pu√≤ verificare che una colonna esista sia in TypeScript che in SQL, ma non verifica che i tipi siano compatibili tra i layer.

**MECCANISMO**:
```yaml
CROSS_LAYER_TYPE_CONSISTENCY:
  trigger: "When referencing a field across TypeScript/SQL/API layers"
  verification_steps:
    1. Extract TypeScript type from types.ts
    2. Extract SQL column type from schema/migration
    3. Extract API response type from endpoint definition
    4. Compare all three for compatibility
  format: |
    TYPE CONSISTENCY CHECK:
    ‚îú‚îÄ Field: created_at
    ‚îú‚îÄ TypeScript: string | null (types.ts:110)
    ‚îú‚îÄ SQL: TIMESTAMP WITH TIME ZONE (schema.sql:45)
    ‚îú‚îÄ API: ISO 8601 string (api/preventivi.ts:78)
    ‚îú‚îÄ Compatibility: ‚úÖ CONSISTENT (SQL TIMESTAMP ‚Üí ISO string ‚Üí TS string)
    
    ‚îú‚îÄ Field: price
    ‚îú‚îÄ TypeScript: number (types.ts:115)
    ‚îú‚îÄ SQL: DECIMAL(10,2) (schema.sql:50)
    ‚îú‚îÄ API: string (api/preventivi.ts:82) ‚ö†Ô∏è MISMATCH
    ‚îî‚îÄ ACTION: API returns string, TypeScript expects number ‚Üí Add parseFloat()
```

**ESEMPIO CONCRETO**:
```
Scenario: Modifica del campo `total_amount` in un preventivo

CROSS_LAYER_TYPE_CONSISTENCY CHECK:
‚îú‚îÄ TypeScript: total_amount: number (types.ts:120)
‚îú‚îÄ SQL: total_amount DECIMAL(12,4) (migrations/001.sql:67)
‚îú‚îÄ API Response: "total_amount": "1234.5678" (string in JSON)
‚îú‚îÄ Frontend Display: toFixed(2) applied
‚îú‚îÄ ISSUE DETECTED: 
‚îÇ   - SQL stores 4 decimal places
‚îÇ   - API returns as string (JSON limitation)
‚îÇ   - Frontend truncates to 2 decimals
‚îÇ   - Rounding errors possible in calculations
‚îî‚îÄ RECOMMENDATION: Standardize to 2 decimals at SQL level OR handle precision explicitly
```

---

### TRANELLO #13: Audit di Completezza delle Condizioni di Errore

**PUNTO CIECO CONTRASTATO**: L'AI tende a gestire solo il "happy path" e i casi di errore pi√π ovvi, ignorando condizioni di errore rare ma critiche.

**MECCANISMO**:
```yaml
ERROR_CONDITION_COMPLETENESS_AUDIT:
  trigger: "Before finalizing any function/component modification"
  required_error_scenarios:
    - null_undefined: "What if the primary input is null/undefined?"
    - empty_collection: "What if the array/object is empty?"
    - network_failure: "What if the API call fails?"
    - timeout: "What if the operation times out?"
    - concurrent_modification: "What if another process modifies the data simultaneously?"
    - permission_denied: "What if the user lacks permissions?"
    - data_corruption: "What if the data format is unexpected?"
  format: |
    ERROR CONDITION AUDIT:
    ‚îú‚îÄ Function: fetchPreventivoDetails(id)
    ‚îú‚îÄ Scenarios analyzed:
    ‚îÇ   ‚îú‚îÄ null_undefined: id is undefined ‚Üí ‚úÖ Handled (early return)
    ‚îÇ   ‚îú‚îÄ empty_collection: preventivo has no items ‚Üí ‚ö†Ô∏è NOT HANDLED
    ‚îÇ   ‚îú‚îÄ network_failure: API returns 500 ‚Üí ‚úÖ Handled (try/catch)
    ‚îÇ   ‚îú‚îÄ timeout: Request exceeds 30s ‚Üí ‚ùå NOT HANDLED
    ‚îÇ   ‚îú‚îÄ concurrent_modification: Another user edits ‚Üí ‚ùå NOT HANDLED
    ‚îÇ   ‚îú‚îÄ permission_denied: User not authorized ‚Üí ‚úÖ Handled (403 check)
    ‚îÇ   ‚îî‚îÄ data_corruption: Malformed JSON ‚Üí ‚ùå NOT HANDLED
    ‚îî‚îÄ ACTIONS REQUIRED: Add timeout, optimistic locking, JSON validation
```

**ESEMPIO CONCRETO**:
```typescript
// BEFORE (incomplete error handling)
async function updatePreventivo(id: string, data: PreventivoUpdate) {
  const response = await api.put(`/preventivi/${id}`, data);
  return response.data;
}

// AFTER (complete error handling per audit)
async function updatePreventivo(id: string, data: PreventivoUpdate) {
  // null_undefined check
  if (!id) throw new ValidationError('ID preventivo richiesto');
  
  // timeout handling
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 30000);
  
  try {
    const response = await api.put(`/preventivi/${id}`, data, {
      signal: controller.signal,
      headers: { 'If-Match': data.etag } // concurrent_modification (optimistic locking)
    });
    
    // data_corruption check
    if (!isValidPreventivoResponse(response.data)) {
      throw new DataCorruptionError('Risposta API malformata');
    }
    
    return response.data;
  } catch (error) {
    if (error.name === 'AbortError') {
      throw new TimeoutError('Timeout aggiornamento preventivo');
    }
    if (error.response?.status === 409) {
      throw new ConcurrentModificationError('Preventivo modificato da altro utente');
    }
    throw error;
  } finally {
    clearTimeout(timeoutId);
  }
}
```

---

## 3. OTTIMIZZAZIONI LINGUISTICHE

### ¬ß 1. VERIFICA OBBLIGATORIA (IDV) - Versione Ottimizzata

**VERSIONE ORIGINALE** (problematica):
> "Ogni colonna/propriet√† citata richiede un IDV nel turno corrente."

**VERSIONE OTTIMIZZATA** (formato strutturato XML con comandi in inglese):

```xml
<rule id="1" name="MANDATORY_VERIFICATION_IDV">
  <command lang="en">
    VERIFY every column/property with IDV in current turn.
    IDV = grep_search OR view_file output showing exact line.
  </command>
  
  <format>
    <template>IDV-T[turn_number]: [column] @ [file]:[line]</template>
    <example>IDV-T3167: owner_ragione_sociale @ types.ts:146</example>
  </format>
  
  <cross_verification required="true">
    <description lang="en">
      If column is used in SQL, MUST verify existence in BOTH:
      1. TypeScript types file
      2. Actual database table/view
    </description>
    <failure_example>
      IDV-T3200: email @ types.ts:48 (TypeScript only - INVALID)
    </failure_example>
    <success_example>
      IDV-T3200: email @ types.ts:48 + SQL SELECT email FROM Anagrafiche LIMIT 1 (VALID)
    </success_example>
  </cross_verification>
  
  <consequence>
    Output without IDV = NULL. MUST regenerate.
  </consequence>
</rule>
```

---

### ¬ß 3. TENTATO SUICIDIO DEL CODICE - Versione Ottimizzata

**VERSIONE ORIGINALE** (ambigua):
> "Dopo ogni piano, scrivi una sezione 'TENTATO SUICIDIO'."

**VERSIONE OTTIMIZZATA**:

```xml
<rule id="3" name="CODE_SUICIDE_ATTEMPT">
  <command lang="en">
    EXECUTE adversarial self-review after EVERY plan.
    GOAL: Prove your solution is WRONG.
  </command>
  
  <mandatory_questions>
    <question id="1" lang="en">
      WHERE ELSE is this logic cloned? 
      EXECUTE: grep_search for exact string/pattern
    </question>
    <question id="2" lang="en">
      WHICH snapshot/fallback could overwrite live data?
      EXECUTE: Search for cache, snapshot, backup patterns
    </question>
    <question id="3" lang="en">
      WHICH distant component (by functional symmetry) is affected?
      EXECUTE: Identify components with similar purpose
    </question>
    <question id="4" lang="en">
      IF this modification fails, WHAT error will user see?
      EXECUTE: Simulate exact error message
    </question>
  </mandatory_questions>
  
  <failure_scenario required="true">
    <description lang="en">
      MUST provide ONE concrete scenario where solution fails.
      Generic scenarios are INVALID.
    </description>
    <invalid_example>
      "Potrebbe fallire se i dati sono nulli" (too generic)
    </invalid_example>
    <valid_example>
      "Fails if owner_ragione_sociale IS NULL AND snapshotAzienda IS empty 
       ‚Üí header displays 'undefined' (verified: no tertiary fallback in code)"
    </valid_example>
  </failure_scenario>
  
  <consequence>
    Plan without concrete failure scenario = REJECTED. MUST regenerate.
  </consequence>
</rule>
```

---

### ¬ß 9. MEMORIA CORROTTA - Versione Ottimizzata

**VERSIONE ORIGINALE** (vaga):
> "Per file > 500 righe, la tua memoria √® CORROTTA dopo 20 turni."

**VERSIONE OTTIMIZZATA**:

```xml
<rule id="9" name="CORRUPTED_MEMORY_PROTOCOL">
  <command lang="en">
    DECLARE memory as CORRUPTED for files > 500 lines after 20 turns.
    MANDATORY re-read before ANY reference.
  </command>
  
  <thresholds>
    <file_size_threshold>500 lines</file_size_threshold>
    <turn_threshold>20 turns</turn_threshold>
    <critical_files auto_refresh="true">
      types.ts, schema.sql, api/endpoints.ts
    </critical_files>
  </thresholds>
  
  <timestamp_declaration required="true">
    <format>
      LAST_ACCESS: [filename] @ Turn [N] ([X] turns ago) ‚Üí [ACTION]
    </format>
    <example>
      LAST_ACCESS: types.ts @ Turn 3167 (34 turns ago) ‚Üí MANDATORY RE-READ
    </example>
    <action_matrix>
      <action turns_ago="0-10">MEMORY VALID - proceed</action>
      <action turns_ago="11-20">MEMORY DEGRADED - verify critical fields</action>
      <action turns_ago="21+">MEMORY CORRUPTED - MUST re-read entire file</action>
    </action_matrix>
  </timestamp_declaration>
  
  <consequence>
    Reference to file > 20 turns old without re-read = OUTPUT INVALID.
  </consequence>
</rule>
```

---

## 4. TEST DI RESISTENZA

### Regola Pi√π Facile da Aggirare: ¬ß 10. FIRMA DI LETTURA (4 Parole)

**VULNERABILIT√Ä IDENTIFICATA**:

La regola richiede 4 parole "non consecutive" dalle frasi guida, ma:
1. Non specifica una distanza minima tra le parole
2. Non verifica che le parole provengano da frasi DIVERSE
3. Permette pattern prevedibili che l'AI pu√≤ memorizzare

**ESEMPIO DI AGGIRAMENTO TECNICO**:
```
Frasi originali:
- "non Inventare mai niente"
- "Non darmi mai ragione per forza"

Firma tecnicamente valida ma elusiva:
"Inventare mai ragione forza" 
‚Üí Parole non consecutive nella singola frase, ma pattern ripetibile
```

**FIX PROPOSTO**:

```xml
<rule id="10" name="READING_SIGNATURE_ENHANCED">
  <command lang="en">
    GENERATE 4-word signature with VERIFIED randomness.
  </command>
  
  <source_phrases>
    <phrase id="1">"non Inventare mai niente"</phrase>
    <phrase id="2">"Non darmi mai ragione per forza"</phrase>
    <phrase id="3">"Non cercare di accontentarmi"</phrase>
    <phrase id="4">"Cerca sempre di capire il contesto, cerca sempre di capire il perch√© voglio fare una cosa"</phrase>
  </source_phrases>
  
  <constraints>
    <constraint id="1">
      Each word MUST come from a DIFFERENT phrase (4 phrases ‚Üí 4 words)
    </constraint>
    <constraint id="2">
      Words MUST NOT form grammatically correct Italian sentence
    </constraint>
    <constraint id="3">
      Include word position in phrase: word[position_in_phrase]
    </constraint>
  </constraints>
  
  <format>
    [word1][pos1] [word2][pos2] [word3][pos3] [word4][pos4]
  </format>
  
  <valid_example>
    Inventare[2] ragione[4] accontentarmi[4] contesto[6]
    ‚Üí From phrases: 1, 2, 3, 4 respectively ‚úÖ
  </valid_example>
  
  <invalid_example>
    Inventare[2] mai[3] niente[4] sempre[1]
    ‚Üí Phrases: 1, 1, 1, 4 ‚Üí INVALID (3 words from same phrase)
  </invalid_example>
  
  <verification>
    Signature MUST be verifiable by checking phrase IDs.
    If verification fails ‚Üí OUTPUT REJECTED.
  </verification>
</rule>
```

---

## 5. INTEGRAZIONE TECNICHE AVANZATE

### ¬ß 1: VERIFICA OBBLIGATORIA (IDV) + Self-Consistency (CoT-SC)

```yaml
section: "¬ß 1 - VERIFICA OBBLIGATORIA"
technique_applied: "Self-Consistency with Chain-of-Thought (CoT-SC)"
implementation: |
  Per ogni IDV critico, esegui 3 verifiche indipendenti:
  1. grep_search per il nome esatto della colonna
  2. view_file del file contenente la definizione
  3. SQL query di test (SELECT colonna FROM tabella LIMIT 1)
  
  REGOLA: Se 2/3 verifiche concordano ‚Üí IDV VALIDO
           Se discordanza ‚Üí INVESTIGARE prima di procedere
expected_impact: "+17% accuracy nella verifica di esistenza colonne"
concrete_example: |
  IDV-T3200: email @ Anagrafiche
  
  VERIFICATION 1 (grep_search): 
    Found "email" in types.ts:48, schema.sql:23, Anagrafiche.tsx:156
  
  VERIFICATION 2 (view_file types.ts:48):
    email: string | null;
  
  VERIFICATION 3 (SQL test):
    SELECT email FROM Anagrafiche LIMIT 1; ‚Üí Returns 'test@example.com'
  
  CONSENSUS: 3/3 ‚úÖ ‚Üí IDV VALIDATED
```

---

### ¬ß 3: TENTATO SUICIDIO + Adversarial Prompting (Red Team)

```yaml
section: "¬ß 3 - TENTATO SUICIDIO DEL CODICE"
technique_applied: "Adversarial Prompting (Red Team)"
implementation: |
  Dopo aver scritto il piano, assumi esplicitamente il ruolo di "Attaccante":
  
  FASE 1 - PIANO (ruolo: Developer)
  [scrivi il piano normale]
  
  FASE 2 - ATTACCO (ruolo: Red Team)
  "Sono un tester malevolo. Come posso far fallire questo piano?"
  - Identifica input edge-case non gestiti
  - Trova race condition possibili
  - Cerca dipendenze non dichiarate
  
  FASE 3 - DIFESA (ruolo: Developer)
  Per ogni attacco identificato, aggiungi mitigazione al piano.
expected_impact: "+30% robustezza delle soluzioni proposte"
concrete_example: |
  PIANO: Aggiornare owner_ragione_sociale con fallback a snapshotAzienda
  
  RED TEAM ATTACK #1:
  "Cosa succede se snapshotAzienda √® un oggetto vuoto {} invece di null?"
  ‚Üí Il fallback owner_ragione_sociale ?? snapshotAzienda.nome passa
  ‚Üí Ma snapshotAzienda.nome √® undefined ‚Üí Display: "undefined"
  
  DIFESA: Aggiungere check esplicito:
  owner_ragione_sociale ?? (snapshotAzienda?.nome || 'Dati non disponibili')
```

---

### ¬ß 7: ANTI-PEZZA + Step-Back Prompting

```yaml
section: "¬ß 7 - ANTI-PEZZA (Analisi Strutturale)"
technique_applied: "Step-Back Prompting"
implementation: |
  Prima di proporre qualsiasi fix, esegui Step-Back:
  
  STEP 1 - ASTRAZIONE:
  "Qual √® il PRINCIPIO GENERALE che questo errore viola?"
  (es. "Single Source of Truth", "Separation of Concerns", "DRY")
  
  STEP 2 - PATTERN RECOGNITION:
  "Dove altro nel codebase questo principio potrebbe essere violato?"
  (grep_search per pattern simili)
  
  STEP 3 - ROOT CAUSE:
  "Perch√© questo principio √® stato violato in primo luogo?"
  (es. "Mancanza di tipo centralizzato", "Copy-paste da altro componente")
  
  STEP 4 - STRUCTURAL FIX:
  "Come posso correggere la STRUTTURA, non solo il SINTOMO?"
expected_impact: "+25% riduzione di fix ripetuti sullo stesso problema"
concrete_example: |
  ERRORE VISIBILE: "Toscana Carrelli" appare invece di "Mvc Toscana Carrelli"
  
  STEP-BACK ANALYSIS:
  
  STEP 1 - PRINCIPIO VIOLATO:
  "Single Source of Truth - L'identit√† aziendale √® definita in pi√π posti"
  
  STEP 2 - PATTERN SEARCH:
  grep_search "Toscana Carrelli" ‚Üí 7 occorrenze in 5 file diversi
  grep_search "ragione_sociale" ‚Üí 23 occorrenze, 12 hardcoded
  
  STEP 3 - ROOT CAUSE:
  "Nessun file di configurazione centralizzato per dati aziendali.
   Ogni componente definisce i propri default."
  
  STEP 4 - STRUCTURAL FIX:
  Creare /config/company.ts con tutti i dati aziendali.
  Refactorare tutti i 5 file per importare da source centralizzata.
  ‚Üí Fix strutturale, non pezza su singolo file.
```

---

### ¬ß 4: ANALISI IMPATTO A DISTANZA + Prompt Chaining

```yaml
section: "¬ß 4 - ANALISI IMPATTO A DISTANZA"
technique_applied: "Prompt Chaining"
implementation: |
  Dividi l'analisi di impatto in 4 prompt sequenziali specializzati:
  
  CHAIN 1 - DETECT:
  "Identifica TUTTI i file che contengono [variabile/funzione modificata]"
  Output: Lista file con righe
  
  CHAIN 2 - CLASSIFY:
  "Per ogni file trovato, classifica la relazione:
   - DIRETTO: usa direttamente la variabile
   - INDIRETTO: importa un modulo che la usa
   - SIMMETRICO: ha funzione analoga
   - REMOTO: potrebbe essere affetto per side-effect"
  Output: Matrice di classificazione
  
  CHAIN 3 - VERIFY:
  "Per ogni file DIRETTO e SIMMETRICO, verifica se la modifica 
   proposta richiede aggiornamenti"
  Output: Lista azioni richieste per file
  
  CHAIN 4 - VALIDATE:
  "Conferma che tutti i file REMOTI sono effettivamente non affetti,
   fornendo evidenza specifica"
  Output: Certificazione di non-impatto
expected_impact: "+35% completezza nell'identificazione di side-effect"
```

---

### ¬ß 2: NEGAZIONI VERIFICATE + Metacognitive Prompting

```yaml
section: "¬ß 2 - NEGAZIONI VERIFICATE"
technique_applied: "Metacognitive Prompting (MP)"
implementation: |
  Applica le 5 fasi metacognitive alle negazioni:
  
  FASE 1 - COMPRENSIONE:
  "Cosa sto cercando di negare e perch√© √® importante?"
  
  FASE 2 - GIUDIZIO PRELIMINARE:
  "La mia prima intuizione √® che [X] NON esiste in [Y]"
  
  FASE 3 - VALUTAZIONE CRITICA:
  "Ma potrebbe esistere con nome diverso? In tabella correlata? 
   Come alias? In una View?"
  
  FASE 4 - RIVALUTAZIONE CON PROVE:
  "Eseguo grep_search per varianti: [X], [X_id], [X_name], [X_ref]"
  
  FASE 5 - CONFIDENCE SCORE:
  "Confidenza nella negazione: [HIGH/MEDIUM/LOW]
   Se LOW ‚Üí cercare ulteriori prove prima di procedere"
expected_impact: "+18% qualit√† delle negazioni, riduzione false negazioni"
concrete_example: |
  NEGAZIONE DA VERIFICARE: "email NON esiste in prev_noleggi"
  
  FASE 1: Verifico che email non sia nella tabella prev_noleggi
  FASE 2: Intuizione - prev_noleggi contiene solo dati noleggio, non contatti
  FASE 3: Challenge - potrebbe esserci email_referente? contact_email? 
  FASE 4: grep_search "email" in schema prev_noleggi ‚Üí 0 risultati
          grep_search "contact" in schema prev_noleggi ‚Üí 0 risultati
          grep_search "referente" in schema prev_noleggi ‚Üí 1 risultato: referente_id (FK)
  FASE 5: Confidenza MEDIUM - email non diretta, ma referente_id potrebbe 
          linkare a tabella con email
  
  NEGAZIONE RAFFINATA:
  ‚ùå email NON esiste DIRETTAMENTE in prev_noleggi
  ‚ö†Ô∏è MA: referente_id (FK) potrebbe linkare a Anagrafiche.email
  üìé AZIONE: Se serve email, JOIN con Anagrafiche via referente_id
```

---

## 6. NUOVE SEZIONI PROPOSTE

### ¬ß 13. VERIFICA DI CONSISTENZA TRANSAZIONALE

```xml
<rule id="13" name="TRANSACTIONAL_CONSISTENCY_CHECK">
  <rationale>
    Le modifiche che coinvolgono pi√π tabelle/file devono essere atomiche.
    L'AI tende a proporre modifiche sequenziali che possono lasciare 
    il sistema in stato inconsistente se interrotte.
  </rationale>
  
  <command lang="en">
    For ANY modification spanning multiple tables/files:
    1. IDENTIFY all entities that must change together
    2. VERIFY that a failure midway leaves system in valid state
    3. PROPOSE rollback strategy for each step
  </command>
  
  <format>
    TRANSACTIONAL ANALYSIS:
    ‚îú‚îÄ Entities involved: [list]
    ‚îú‚îÄ Atomicity requirement: [YES/NO]
    ‚îú‚îÄ If YES:
    ‚îÇ   ‚îú‚îÄ Transaction boundary: [START...END]
    ‚îÇ   ‚îú‚îÄ Rollback strategy: [description]
    ‚îÇ   ‚îî‚îÄ Partial failure state: [what happens if step N fails]
    ‚îî‚îÄ If NO:
        ‚îî‚îÄ Justification: [why independent updates are safe]
  </format>
  
  <example>
    TASK: Update company name from "Toscana Carrelli" to "Mvc Toscana Carrelli"
    
    TRANSACTIONAL ANALYSIS:
    ‚îú‚îÄ Entities involved:
    ‚îÇ   ‚îú‚îÄ Anagrafiche.ragione_sociale (DB)
    ‚îÇ   ‚îú‚îÄ config/company.ts (Code)
    ‚îÇ   ‚îú‚îÄ LetterheadPDF.tsx (Template)
    ‚îÇ   ‚îú‚îÄ EmailSignature.tsx (Template)
    ‚îÇ   ‚îî‚îÄ invoice_template.html (Asset)
    ‚îú‚îÄ Atomicity requirement: YES
    ‚îÇ   (Mixed old/new names would confuse customers)
    ‚îú‚îÄ Transaction boundary:
    ‚îÇ   START: Begin DB transaction
    ‚îÇ   1. UPDATE Anagrafiche
    ‚îÇ   2. UPDATE config/company.ts
    ‚îÇ   3. UPDATE all templates
    ‚îÇ   4. Clear cache
    ‚îÇ   COMMIT: All or nothing
    ‚îú‚îÄ Rollback strategy:
    ‚îÇ   - DB: ROLLBACK transaction
    ‚îÇ   - Code: git revert
    ‚îÇ   - Cache: Already cleared, will rebuild with correct data
    ‚îî‚îÄ Partial failure state:
        If step 3 fails ‚Üí DB shows new name, templates show old
        ‚Üí Customer sees inconsistent branding
        ‚Üí UNACCEPTABLE ‚Üí Must be atomic
  </example>
  
  <consequence>
    Multi-entity modification without transactional analysis = REJECTED.
  </consequence>
</rule>
```

---

### ¬ß 14. AUDIT DI REGRESSIONE PREVENTIVA

```xml
<rule id="14" name="PREVENTIVE_REGRESSION_AUDIT">
  <rationale>
    Ogni modifica pu√≤ introdurre regressioni in funzionalit√† esistenti.
    L'AI deve identificare proattivamente i test che potrebbero fallire
    PRIMA di proporre la modifica.
  </rationale>
  
  <command lang="en">
    Before ANY code modification:
    1. IDENTIFY existing tests that cover the modified code
    2. PREDICT which tests might fail after modification
    3. PROPOSE test updates OR justify why tests remain valid
  </command>
  
  <format>
    REGRESSION AUDIT:
    ‚îú‚îÄ Modified file: [filename]
    ‚îú‚îÄ Related tests found: [list with grep_search evidence]
    ‚îú‚îÄ Tests at risk:
    ‚îÇ   ‚îú‚îÄ [test_name]: [why it might fail]
    ‚îÇ   ‚îî‚îÄ [test_name]: [why it might fail]
    ‚îú‚îÄ Tests confirmed safe:
    ‚îÇ   ‚îî‚îÄ [test_name]: [why it won't be affected]
    ‚îî‚îÄ Required test updates:
        ‚îî‚îÄ [test_name]: [specific change needed]
  </format>
  
  <example>
    MODIFICATION: Change fallback logic in usePreventiviNoleggio.ts
    
    REGRESSION AUDIT:
    ‚îú‚îÄ Modified file: usePreventiviNoleggio.ts
    ‚îú‚îÄ Related tests found:
    ‚îÇ   ‚îú‚îÄ usePreventiviNoleggio.test.ts (grep: "usePreventiviNoleggio")
    ‚îÇ   ‚îî‚îÄ PreventiviNoleggio.integration.test.ts
    ‚îú‚îÄ Tests at risk:
    ‚îÇ   ‚îú‚îÄ "should display owner name": 
    ‚îÇ   ‚îÇ   Currently expects exact string "Toscana Carrelli"
    ‚îÇ   ‚îÇ   Will fail with new fallback logic
    ‚îÇ   ‚îî‚îÄ "should handle null owner":
    ‚îÇ       Currently expects empty string
    ‚îÇ       Will fail - now returns "Dati non disponibili"
    ‚îú‚îÄ Tests confirmed safe:
    ‚îÇ   ‚îî‚îÄ "should fetch preventivi list": 
    ‚îÇ       Tests API call, not display logic
    ‚îî‚îÄ Required test updates:
        ‚îú‚îÄ "should display owner name": 
        ‚îÇ   Change expected value to "Mvc Toscana Carrelli"
        ‚îî‚îÄ "should handle null owner":
            Change expected value to "Dati non disponibili"
  </example>
  
  <no_tests_found_protocol>
    If no related tests found:
    1. FLAG as HIGH RISK modification
    2. PROPOSE minimum test coverage before proceeding
    3. Document untested code paths
  </no_tests_found_protocol>
  
  <consequence>
    Modification without regression audit = BLOCKED until audit complete.
  </consequence>
</rule>
```

---

# TASK 2: RICERCA AGGIORNATA E PROPOSTE INNOVATIVE

---

## 1. RICERCHE ESEGUITE

La ricerca parallela ha coperto 5 aree tematiche distinte, con le seguenti query e fonti:

| Area Tematica | Query di Ricerca | Fonti Principali |
|---------------|------------------|------------------|
| Prompt Engineering 2024-2025 | "Ultimi studi prompt engineering 2024 2025 LLM techniques" | Medium, Reddit r/PromptEngineering, news.aakashg.com |
| Anti-Hallucination | "Anti-hallucination techniques LLM 2024 2025 grounding verification" | Nature, Lakera.ai |
| Constrained Generation | "Constrained generation new approaches 2024 2025 structured prompts" | arXiv, ACL Anthology |
| Multilingual Prompting | "Multilingual prompting techniques 2024 2025 cross-lingual" | arXiv, ScienceDirect |
| Benchmark Structured Prompts | "Benchmark structured prompts LLM accuracy 2024 2025" | arXiv, TechRxiv |

---

## 2. TECNICHE INNOVATIVE IDENTIFICATE

### Tecnica 1: Recursive Self-Improvement Prompting (RSIP)

```yaml
tecnica_1:
  nome: "Recursive Self-Improvement Prompting (RSIP)"
  fonte: "https://aloaguilar20.medium.com/the-complete-prompt-engineering-guide-for-2025-mastering-cutting-edge-techniques-dfe0591b1d31"
  data_pubblicazione: "2025"
  descrizione: |
    Processo iterativo in cui il modello AI genera un output iniziale, 
    critica autonomamente il proprio lavoro rispetto a criteri specifici, 
    e genera una versione migliorata basata su quella critica. 
    Il ciclo si ripete con criteri di valutazione diversi ad ogni iterazione.
  applicabilit√†_regole_anti_approssimazione:
    score: 9
    motivazione: |
      L'autocritica iterativa pu√≤ essere indirizzata specificamente 
      a eliminare approssimazioni e verificare il rispetto delle regole.
      Il raffinamento progressivo √® ideale per la correzione di deviazioni.
  implementazione_proposta:
    sezione_target: "¬ß 3 - TENTATO SUICIDIO DEL CODICE"
    meccanismo_concreto: |
      Dopo ogni piano, esegui 3 cicli RSIP:
      
      CICLO 1 - Critica su COMPLETEZZA:
      "Il mio piano copre tutti i file affetti? Mancano verifiche?"
      ‚Üí Genera versione migliorata
      
      CICLO 2 - Critica su CORRETTEZZA:
      "Le mie assunzioni sono verificate con IDV? Ho negazioni sufficienti?"
      ‚Üí Genera versione migliorata
      
      CICLO 3 - Critica su ROBUSTEZZA:
      "Quali edge case non ho considerato? Dove pu√≤ fallire?"
      ‚Üí Genera versione finale
    esempio_pratico: |
      PIANO INIZIALE: Aggiornare owner_ragione_sociale in PreventiviNoleggio.tsx
      
      RSIP CICLO 1 (COMPLETEZZA):
      Critica: "Ho verificato solo 1 file, ma grep mostra 5 occorrenze"
      Miglioramento: Aggiungere tutti i 5 file al piano
      
      RSIP CICLO 2 (CORRETTEZZA):
      Critica: "IDV mancante per 2 file, negazione non verificata per View"
      Miglioramento: Aggiungere IDV per tutti, verificare View
      
      RSIP CICLO 3 (ROBUSTEZZA):
      Critica: "Nessun handling per owner_ragione_sociale = NULL"
      Miglioramento: Aggiungere fallback esplicito con test
```

---

### Tecnica 2: Calibrated Confidence Prompting (CCP)

```yaml
tecnica_2:
  nome: "Calibrated Confidence Prompting (CCP)"
  fonte: "https://www.reddit.com/r/PromptEngineering/comments/1k7jrt7/advanced_prompt_engineering_techniques_for_2025/"
  data_pubblicazione: "2025"
  descrizione: |
    Metodo per migliorare l'affidabilit√† richiedendo al modello di assegnare 
    un livello di confidenza esplicito a ogni affermazione. Il modello usa 
    una scala predefinita e fornisce la base per la sua confidenza, 
    prevenendo la presentazione overconfident di informazioni incerte.
  applicabilit√†_regole_anti_approssimazione:
    score: 9
    motivazione: |
      Richiedere dichiarazione di confidenza rende il modello pi√π consapevole 
      dell'incertezza. Permette di individuare e revisionare affermazioni 
      a bassa confidenza, che sono pi√π inclini all'approssimazione.
  implementazione_proposta:
    sezione_target: "¬ß 1 - VERIFICA OBBLIGATORIA (IDV)"
    meccanismo_concreto: |
      Per ogni IDV, aggiungere CONFIDENCE LEVEL obbligatorio:
      
      SCALA DI CONFIDENZA:
      - VERIFIED (100%): Confermato con grep_search + view_file + SQL test
      - HIGH (80-99%): Confermato con 2/3 metodi di verifica
      - MEDIUM (50-79%): Confermato con 1 metodo, pattern coerente
      - LOW (20-49%): Basato su convenzioni, non verificato direttamente
      - SPECULATIVE (<20%): Assunzione senza evidenza
      
      REGOLA: Output con confidenza < MEDIUM per campi critici = BLOCCATO
    esempio_pratico: |
      IDV-T3200: owner_ragione_sociale @ types.ts:146
      CONFIDENCE: VERIFIED (100%)
      BASIS: 
        ‚úÖ grep_search: trovato in types.ts:146
        ‚úÖ view_file: confermato tipo "string | null"
        ‚úÖ SQL test: SELECT owner_ragione_sociale FROM v_preventivi LIMIT 1 ‚Üí OK
      
      IDV-T3201: legacy_owner_name @ types.ts:???
      CONFIDENCE: SPECULATIVE (15%)
      BASIS:
        ‚ùå grep_search: non trovato
        ‚ùå Assunzione basata su naming convention
      ACTION: ‚õî BLOCCATO - Verificare esistenza prima di procedere
```

---

### Tecnica 3: Retrieval-Augmented Generation with Span-Level Verification

```yaml
tecnica_3:
  nome: "RAG with Span-Level Verification"
  fonte: "https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models"
  data_pubblicazione: "2024-2025"
  descrizione: |
    Estende il RAG tradizionale verificando ogni claim generato 
    contro l'evidenza recuperata a livello di span (porzione di testo).
    Ogni affermazione deve essere tracciabile a una fonte specifica.
  applicabilit√†_regole_anti_approssimazione:
    score: 9
    motivazione: |
      Combina il grounding del RAG con verifica puntuale, forzando 
      il modello a basare le risposte su prove concrete e verificarne 
      la correttezza a livello granulare.
  implementazione_proposta:
    sezione_target: "¬ß 6 - SQL SICURO"
    meccanismo_concreto: |
      Per ogni colonna in una query SQL, richiedere SPAN VERIFICATION:
      
      SPAN VERIFICATION FORMAT:
      [colonna] ‚Üí [file]:[riga_inizio]-[riga_fine] ‚Üí "[testo esatto]"
      
      Ogni colonna deve avere uno span verificabile che ne conferma:
      1. Esistenza
      2. Tipo
      3. Contesto d'uso
    esempio_pratico: |
      SQL: SELECT owner_ragione_sociale, created_at FROM v_preventivi
      
      SPAN VERIFICATION:
      
      owner_ragione_sociale ‚Üí types.ts:146-148 ‚Üí 
        "owner_ragione_sociale: string | null; // Ragione sociale del proprietario"
      
      created_at ‚Üí types.ts:110-112 ‚Üí
        "created_at: string; // ISO 8601 timestamp, e.g., '2024-01-15T10:30:00Z'"
      
      v_preventivi ‚Üí schema.sql:234-256 ‚Üí
        "CREATE VIEW v_preventivi AS SELECT ... owner_ragione_sociale ... FROM ..."
      
      ‚úÖ All spans verified - SQL APPROVED
```

---

### Tecnica 4: Logic-of-Thought (LoT)

```yaml
tecnica_4:
  nome: "Logic-of-Thought (LoT)"
  fonte: "https://aclanthology.org/2025.naacl-long.510/"
  data_pubblicazione: "2025 (NAACL)"
  descrizione: |
    Inietta la logica formale nei prompt per garantire coerenza.
    Il modello deve esplicitare le premesse logiche, le inferenze,
    e verificare che le conclusioni seguano validamente dalle premesse.
  applicabilit√†_regole_anti_approssimazione:
    score: 10
    motivazione: |
      L'approccio pi√π rigoroso identificato. Forza il modello a 
      strutturare il ragionamento in forma logica verificabile,
      eliminando salti logici e assunzioni implicite.
  implementazione_proposta:
    sezione_target: "Nuova sezione ¬ß 15"
    meccanismo_concreto: |
      Per ogni decisione critica, richiedere LOGIC TRACE:
      
      LOGIC TRACE FORMAT:
      PREMISE 1: [affermazione verificata con IDV]
      PREMISE 2: [affermazione verificata con IDV]
      ...
      INFERENCE RULE: [modus ponens / modus tollens / etc.]
      CONCLUSION: [deve seguire logicamente dalle premesse]
      VALIDITY CHECK: [la conclusione √® valida? SI/NO + giustificazione]
    esempio_pratico: |
      DECISIONE: Usare snapshotAzienda.nome come fallback per owner_ragione_sociale
      
      LOGIC TRACE:
      
      PREMISE 1: owner_ragione_sociale pu√≤ essere NULL (IDV-T3200: types.ts:146)
      PREMISE 2: snapshotAzienda.nome contiene il nome azienda al momento del preventivo
                 (IDV-T3201: usePreventiviNoleggio.ts:89)
      PREMISE 3: Se owner_ragione_sociale √® NULL, l'utente deve comunque vedere un nome
                 (Requisito funzionale: UI non deve mostrare "undefined")
      
      INFERENCE RULE: Modus Ponens
      - Se P1 (owner pu√≤ essere NULL) AND P3 (serve sempre un nome visibile)
      - Allora serve un fallback
      
      CONCLUSION: snapshotAzienda.nome √® un fallback valido
      
      VALIDITY CHECK: ‚úÖ VALIDO
      - La conclusione segue dalle premesse
      - MA: Aggiungere PREMISE 4: snapshotAzienda.nome non √® mai NULL?
        ‚Üí Verifica: grep_search "snapshotAzienda" ‚Üí pu√≤ essere {} vuoto
        ‚Üí CONCLUSIONE RAFFINATA: Serve fallback terziario per snapshotAzienda vuoto
```

---

### Tecnica 5: Cross-Layer Attention Probing (CLAP)

```yaml
tecnica_5:
  nome: "Cross-Layer Attention Probing (CLAP)"
  fonte: "https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models"
  data_pubblicazione: "2024"
  descrizione: |
    Addestra classificatori leggeri sulle attivazioni interne del modello 
    per rilevare probabili allucinazioni in tempo reale. Analizza i pattern 
    di attenzione tra i layer per identificare quando il modello sta 
    "inventando" invece di "ricordando".
  applicabilit√†_regole_anti_approssimazione:
    score: 7
    motivazione: |
      Tecnica promettente per rilevamento in tempo reale, ma richiede 
      accesso agli interni del modello. Applicabile principalmente 
      a livello di sistema, non di prompt.
  implementazione_proposta:
    sezione_target: "¬ß 12 - CHECKLIST PRE-OUTPUT"
    meccanismo_concreto: |
      Simulare CLAP a livello di prompt con "Confidence Markers":
      
      Per ogni affermazione nell'output, il modello deve indicare:
      - [RECALL]: Informazione recuperata da contesto/file letti
      - [INFERENCE]: Deduzione logica da informazioni note
      - [ASSUMPTION]: Assunzione non verificata
      - [SPECULATION]: Ipotesi senza base concreta
      
      REGOLA: Output con > 20% [ASSUMPTION] + [SPECULATION] = RIFIUTATO
    esempio_pratico: |
      OUTPUT CON CONFIDENCE MARKERS:
      
      "La colonna owner_ragione_sociale [RECALL: types.ts:146] √® di tipo 
      string | null [RECALL: types.ts:146]. Quando √® NULL, il sistema 
      dovrebbe [INFERENCE: da requisito UI] mostrare un fallback. 
      Il fallback pi√π appropriato √® snapshotAzienda.nome [ASSUMPTION: 
      non verificato se sempre popolato]. In alternativa, si potrebbe 
      usare 'N/A' [SPECULATION: convenzione comune ma non verificata 
      nel codebase]."
      
      ANALYSIS:
      - RECALL: 2 (50%)
      - INFERENCE: 1 (25%)
      - ASSUMPTION: 1 (25%)
      - SPECULATION: 0 (0%)
      
      ASSUMPTION + SPECULATION = 25% > 20% threshold
      ‚Üí ‚ö†Ô∏è WARNING: Verificare assumption prima di procedere
```

---

### Tecnica 6: Language-to-Thought (L2T) Prompting

```yaml
tecnica_6:
  nome: "Language-to-Thought (L2T) Prompting"
  fonte: "https://arxiv.org/pdf/2505.24409"
  data_pubblicazione: "2025"
  descrizione: |
    Strategia che allinea il linguaggio di "pensiero" interno del modello 
    con la fonte della conoscenza. Sfida l'assunto del beneficio universale 
    del ragionamento in inglese, esplorando quando √® meglio ragionare 
    nella lingua dei dati sorgente.
  applicabilit√†_regole_anti_approssimazione:
    score: 6
    motivazione: |
      Rilevante per codebase multilingue o con commenti/documentazione 
      in italiano. Pu√≤ migliorare la comprensione di contesto culturale 
      e convenzioni locali.
  implementazione_proposta:
    sezione_target: "¬ß 5 - STANDARD AI vs LOGICA UTENTE"
    meccanismo_concreto: |
      Quando si analizza codice con commenti/naming in italiano:
      
      1. IDENTIFY language of source (comments, variable names, docs)
      2. If source is Italian, reason about business logic in Italian
      3. Translate only technical commands to English
      4. Preserve Italian terms for domain-specific concepts
    esempio_pratico: |
      CODICE SORGENTE:
      // Calcola il totale del preventivo includendo IVA
      const calcolaTotalePreventivo = (imponibile: number) => {
        const aliquotaIVA = 0.22; // 22% standard italiano
        return imponibile * (1 + aliquotaIVA);
      }
      
      L2T REASONING (in Italian for business logic):
      "Il calcolo usa l'aliquota IVA italiana standard del 22%.
       ATTENZIONE: In Italia esistono anche aliquote ridotte (10%, 4%).
       VERIFICA: Il preventivo riguarda beni/servizi ad aliquota standard?
       Se noleggio macchinari ‚Üí 22% corretto.
       Se alimentari ‚Üí potrebbe essere 10% o 4%."
      
      TECHNICAL COMMAND (in English):
      VERIFY: grep_search "aliquotaIVA" to find all tax rate usages
      CHECK: Are there cases where reduced VAT rates should apply?
```

---

### Tecnica 7: Logical Chain-of-Thought (LogiCoT)

```yaml
tecnica_7:
  nome: "Logical Chain-of-Thought (LogiCoT)"
  fonte: "https://arxiv.org/abs/2402.07927"
  data_pubblicazione: "2024"
  descrizione: |
    Unisce il ragionamento a catena di pensiero con la logica simbolica 
    per migliorare la coerenza e la verificabilit√†. Ogni passo del 
    ragionamento deve essere esprimibile in forma logica.
  applicabilit√†_regole_anti_approssimazione:
    score: 9
    motivazione: |
      La combinazione di CoT e logica formale aumenta trasparenza e 
      verificabilit√†, rendendo il processo meno soggetto ad approssimazioni.
  implementazione_proposta:
    sezione_target: "¬ß 7 - ANTI-PEZZA"
    meccanismo_concreto: |
      Per ogni diagnosi di problema, richiedere LogiCoT:
      
      STEP 1: Osservazione (O)
      STEP 2: Ipotesi (H) derivata da O
      STEP 3: Predizione (P) se H √® vera
      STEP 4: Test (T) per verificare P
      STEP 5: Conclusione (C) basata su risultato T
      
      Ogni step deve essere collegato logicamente al precedente.
    esempio_pratico: |
      PROBLEMA: Header PDF mostra "Toscana Carrelli" invece di "Mvc Toscana Carrelli"
      
      LogiCoT ANALYSIS:
      
      O (Osservazione): 
        PDF header mostra "Toscana Carrelli"
        Database contiene "Mvc Toscana Carrelli"
      
      H (Ipotesi): 
        IF DB ha valore corretto AND PDF mostra valore errato
        THEN il problema √® nel layer di rendering, non nei dati
      
      P (Predizione):
        IF H √® vera THEN trover√≤ hardcoded string in LetterheadPDF.tsx
      
      T (Test):
        grep_search "Toscana Carrelli" in LetterheadPDF.tsx
        RISULTATO: Trovato @ riga 45: const companyName = "Toscana Carrelli"
      
      C (Conclusione):
        H CONFERMATA: Il valore √® hardcoded nel componente PDF
        ROOT CAUSE: Mancanza di centralizzazione dati aziendali
        FIX: Sostituire hardcoded con import da config/company.ts
```

---

## 3. PROPOSTA INTEGRATIVA COMPLETA

### Nuova Sezione ¬ß 15: LOGIC-OF-THOUGHT VERIFICATION (LoTV)

Basata sulla tecnica Logic-of-Thought (LoT) identificata nella ricerca, questa sezione integra la verifica logica formale nel processo anti-approssimazione.

```xml
<rule id="15" name="LOGIC_OF_THOUGHT_VERIFICATION">
  <rationale>
    L'AI tende a fare salti logici impliciti che introducono approssimazioni.
    Forzare l'esplicitazione della catena logica rende visibili le assunzioni
    nascoste e permette la loro verifica.
  </rationale>
  
  <command lang="en">
    For EVERY decision or conclusion, EXECUTE Logic-of-Thought Verification:
    1. STATE all premises explicitly
    2. VERIFY each premise with IDV
    3. DECLARE inference rule used
    4. DERIVE conclusion formally
    5. CHECK validity of derivation
  </command>
  
  <logic_trace_format>
    <template>
      LOGIC TRACE [decision_id]:
      ‚îú‚îÄ PREMISES:
      ‚îÇ   ‚îú‚îÄ P1: [statement] (IDV: [reference])
      ‚îÇ   ‚îú‚îÄ P2: [statement] (IDV: [reference])
      ‚îÇ   ‚îî‚îÄ P3: [statement] (IDV: [reference])
      ‚îú‚îÄ INFERENCE RULE: [rule_name]
      ‚îÇ   ‚îî‚îÄ Pattern: [formal pattern, e.g., "If P1 AND P2 THEN C"]
      ‚îú‚îÄ CONCLUSION: [derived statement]
      ‚îú‚îÄ VALIDITY: [VALID/INVALID]
      ‚îÇ   ‚îî‚îÄ Justification: [why conclusion follows/doesn't follow]
      ‚îî‚îÄ HIDDEN ASSUMPTIONS CHECK:
          ‚îî‚îÄ [list any unstated assumptions required for conclusion]
    </template>
  </logic_trace_format>
  
  <inference_rules_allowed>
    <rule name="Modus Ponens">If P, and P implies Q, then Q</rule>
    <rule name="Modus Tollens">If P implies Q, and not Q, then not P</rule>
    <rule name="Hypothetical Syllogism">If P implies Q, and Q implies R, then P implies R</rule>
    <rule name="Disjunctive Syllogism">If P or Q, and not P, then Q</rule>
    <rule name="Conjunction">If P, and Q, then P and Q</rule>
  </inference_rules_allowed>
  
  <example>
    DECISION: Use snapshotAzienda.nome as fallback for null owner_ragione_sociale
    
    LOGIC TRACE [LT-001]:
    ‚îú‚îÄ PREMISES:
    ‚îÇ   ‚îú‚îÄ P1: owner_ragione_sociale can be NULL 
    ‚îÇ   ‚îÇ      (IDV-T3200: types.ts:146 ‚Üí "owner_ragione_sociale: string | null")
    ‚îÇ   ‚îú‚îÄ P2: UI must always display a company name (no "undefined")
    ‚îÇ   ‚îÇ      (IDV-T3201: requirements.md:45 ‚Üí "Company name required in all views")
    ‚îÇ   ‚îî‚îÄ P3: snapshotAzienda.nome contains company name at preventivo creation
    ‚îÇ          (IDV-T3202: usePreventiviNoleggio.ts:89 ‚Üí "snapshotAzienda: {...}")
    ‚îú‚îÄ INFERENCE RULE: Hypothetical Syllogism
    ‚îÇ   ‚îî‚îÄ Pattern: 
    ‚îÇ       If owner_ragione_sociale is NULL (P1 condition met)
    ‚îÇ       AND UI requires a name (P2)
    ‚îÇ       AND snapshotAzienda.nome has a name (P3)
    ‚îÇ       THEN snapshotAzienda.nome can serve as fallback
    ‚îú‚îÄ CONCLUSION: snapshotAzienda.nome is a valid fallback
    ‚îú‚îÄ VALIDITY: CONDITIONALLY VALID
    ‚îÇ   ‚îî‚îÄ Justification: Conclusion follows IF P3 is always true
    ‚îî‚îÄ HIDDEN ASSUMPTIONS CHECK:
        ‚îú‚îÄ ‚ö†Ô∏è ASSUMPTION: snapshotAzienda is never null/undefined
        ‚îÇ   ‚Üí VERIFY: grep_search "snapshotAzienda" for null checks
        ‚îÇ   ‚Üí RESULT: Can be empty object {} ‚Üí ASSUMPTION INVALID
        ‚îú‚îÄ ‚ö†Ô∏è ASSUMPTION: snapshotAzienda.nome is never empty string
        ‚îÇ   ‚Üí VERIFY: Check data validation rules
        ‚îÇ   ‚Üí RESULT: No validation found ‚Üí ASSUMPTION UNVERIFIED
        ‚îî‚îÄ ACTION REQUIRED:
            Add tertiary fallback: owner_ragione_sociale ?? snapshotAzienda?.nome ?? 'Dati non disponibili'
  </example>
  
  <consequence>
    Decision without valid Logic Trace = BLOCKED.
    Decision with hidden assumptions = MUST verify assumptions before proceeding.
  </consequence>
  
  <integration_with_existing_rules>
    <integration rule="¬ß1">Each premise MUST have IDV</integration>
    <integration rule="¬ß2">Hidden assumptions become Negazioni Verificate</integration>
    <integration rule="¬ß3">Invalid logic trace triggers Tentato Suicidio</integration>
  </integration_with_existing_rules>
</rule>
```

---

## 4. COMPARATIVE ANALYSIS

```yaml
comparative_matrix:
  - tecnica: "Recursive Self-Improvement Prompting (RSIP)"
    simile_a: "Chain-of-Thought (CoT)"
    differenze_chiave: |
      - CoT: Ragionamento lineare, single-pass
      - RSIP: Ragionamento iterativo con auto-critica e raffinamento
      - RSIP aggiunge loop di feedback esplicito
    vantaggio: |
      Quando il task richiede alta precisione e c'√® tempo per iterazioni.
      Ideale per piani complessi dove errori hanno alto costo.
    svantaggio: |
      Pi√π lento (3+ iterazioni). Non adatto per risposte rapide.
      Richiede criteri di valutazione ben definiti.

  - tecnica: "Calibrated Confidence Prompting (CCP)"
    simile_a: "Metacognitive Prompting (MP)"
    differenze_chiave: |
      - MP: Focus su processo di pensiero (5 fasi cognitive)
      - CCP: Focus su output (ogni affermazione ha confidence score)
      - CCP √® pi√π granulare e verificabile
    vantaggio: |
      Quando serve tracciabilit√† di ogni singola affermazione.
      Permette filtering automatico di contenuto low-confidence.
    svantaggio: |
      Overhead significativo per output lunghi.
      Richiede scala di confidenza ben calibrata.

  - tecnica: "Logic-of-Thought (LoT)"
    simile_a: "Chain-of-Thought (CoT)"
    differenze_chiave: |
      - CoT: Ragionamento in linguaggio naturale
      - LoT: Ragionamento con struttura logica formale
      - LoT richiede premesse esplicite e regole di inferenza
    vantaggio: |
      Quando serve verificabilit√† formale delle conclusioni.
      Ideale per decisioni critiche in sistemi enterprise.
    svantaggio: |
      Richiede familiarit√† con logica formale.
      Pu√≤ essere verbose per decisioni semplici.

  - tecnica: "RAG with Span-Level Verification"
    simile_a: "Structured Output + Delimiters"
    differenze_chiave: |
      - Structured Output: Forza formato, non verifica contenuto
      - Span-Level RAG: Verifica che ogni claim sia tracciabile a fonte
      - Span-Level √® pi√π rigoroso ma richiede knowledge base
    vantaggio: |
      Quando serve tracciabilit√† completa delle fonti.
      Elimina hallucination su fatti verificabili.
    svantaggio: |
      Richiede sistema RAG configurato.
      Non applicabile a ragionamento puramente logico.

  - tecnica: "LogiCoT"
    simile_a: "Step-Back Prompting"
    differenze_chiave: |
      - Step-Back: Astrazione prima, poi applicazione
      - LogiCoT: Ogni step √® verificabile logicamente
      - LogiCoT mantiene rigore formale attraverso tutto il processo
    vantaggio: |
      Quando serve audit trail completo del ragionamento.
      Ideale per debugging di conclusioni errate.
    svantaggio: |
      Pi√π strutturato = meno flessibile per problemi mal definiti.
```

---

## 5. PRIORITIZZAZIONE PER IMPATTO

| Priorit√† | Tecnica | Impatto Atteso | Effort Implementazione | ROI |
|----------|---------|----------------|------------------------|-----|
| **HIGH** | Logic-of-Thought (LoT) | -50% salti logici, +40% verificabilit√† | Medio | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **HIGH** | Calibrated Confidence Prompting (CCP) | -35% affermazioni non verificate | Basso | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **HIGH** | RSIP | +30% qualit√† piani complessi | Medio | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **MEDIUM** | RAG Span-Level Verification | -45% hallucination su fatti | Alto | ‚≠ê‚≠ê‚≠ê |
| **MEDIUM** | LogiCoT | +25% tracciabilit√† ragionamento | Medio | ‚≠ê‚≠ê‚≠ê |
| **MEDIUM** | L2T Prompting | +15% comprensione contesto locale | Basso | ‚≠ê‚≠ê‚≠ê |
| **LOW** | CLAP (simulato) | +10% detection approssimazioni | Alto | ‚≠ê‚≠ê |

---

## AUTOVALUTAZIONE OBBLIGATORIA

```yaml
self_validation:
  task_1_completato:
    - punti_ciechi: "4 identificati ‚úÖ (> 3 richiesti)"
    - tranelli: "2 proposti ‚úÖ (= 2 richiesti)"
    - ottimizzazioni_linguistiche: "3 sezioni riformulate in XML ‚úÖ"
    - test_resistenza: "¬ß10 testato con fix proposto ‚úÖ"
    - tecniche_avanzate: "5 integrate ‚úÖ (> 3 richieste)"
    
  task_2_completato:
    - web_search_eseguita: "SI ‚úÖ (5 ricerche parallele)"
    - tecniche_nuove: "7 trovate ‚úÖ (> 3 richieste)"
    - fonti_verificate: "URL citati per ogni tecnica ‚úÖ"
    - date_recenti: "2024-2025 ‚úÖ"
    - comparative_analysis: "5 confronti completati ‚úÖ"
    
  quality_check:
    - specificit√†: "Esempi concreti per ogni proposta ‚úÖ"
    - implementabilit√†: "Codice/XML/YAML forniti ‚úÖ"
    - no_invenzioni: "Tutte le tecniche con fonte verificabile ‚úÖ"
    - formato_strutturato: "YAML/XML usati per tutte le sezioni tecniche ‚úÖ"
    - impatto_misurabile: "Metriche dichiarate per ogni tecnica ‚úÖ"

validation_result: PASS ‚úÖ
```

---

## FONTI VERIFICATE

1. **Prompt Engineering Guide 2025** - Medium (aloaguilar20)
   - URL: https://aloaguilar20.medium.com/the-complete-prompt-engineering-guide-for-2025-mastering-cutting-edge-techniques-dfe0591b1d31
   - Tecniche: RSIP, CAD

2. **Advanced Prompt Engineering Techniques 2025** - Reddit r/PromptEngineering
   - URL: https://www.reddit.com/r/PromptEngineering/comments/1k7jrt7/advanced_prompt_engineering_techniques_for_2025/
   - Tecniche: CCP, MPS, CHI

3. **Guide to Hallucinations in LLMs** - Lakera.ai
   - URL: https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models
   - Tecniche: CLAP, RAG Span-Level, MetaQA

4. **Logic-of-Thought** - ACL Anthology (NAACL 2025)
   - URL: https://aclanthology.org/2025.naacl-long.510/
   - Tecnica: LoT

5. **Prompt Engineering Survey 2024** - arXiv
   - URL: https://arxiv.org/abs/2402.07927
   - Tecniche: LogiCoT, S2A, ThoT

6. **Language-to-Thought Prompting** - arXiv
   - URL: https://arxiv.org/pdf/2505.24409
   - Tecnica: L2T

7. **Scope Expansion Techniques** - TechRxiv
   - URL: https://www.techrxiv.org/doi/full/10.36227/techrxiv.174352305.54908314
   - Tecnica: Scope Expansion

---

**FIRMA DI LETTURA**: Inventare[2] ragione[4] accontentarmi[4] contesto[6]

