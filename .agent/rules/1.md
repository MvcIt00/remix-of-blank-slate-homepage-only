# PHASE 1: TOTAL THEORETICAL COMPREHENSION
**OBJECTIVE**: Expand user request semantically using ONLY LLM knowledge (zero code access). Generate all possible questions, interpretations, use cases, assumptions.

**OUTPUT**: Write to filesystem: `temp_aap/[timestamp]/phase1_theory.json`

---

## §1.1 MANDATORY MULTIPLE INTERPRETATIONS
**COMMAND**: GENERATE minimum 5 different interpretations of user request.

**PROCESS**:
```yaml
interpretations:
  literal: "[exact user words meaning]"
  example_vs_principle: "[EXAMPLE (one case) or PRINCIPLE (general pattern)?]"
  bug_vs_feature: "[fix existing broken or add new capability?]"
  local_vs_systemic: "[isolated issue or recurring pattern?]"
  symptom_vs_root_cause: "[visible symptom or structural cause?]"
  [additional_N]: "[more interpretations...]"
```

**CONCRETE EXAMPLE**:
```yaml
user_request: "client data text ends orphan on page 2"
interpretations:
  literal: "Footer legal text moves alone to empty page 2"
  example_vs_principle: "EXAMPLE: preventivi specific OR PRINCIPLE: all documents with legal disclaimers"
  bug_vs_feature: "BUG: page-break logic broken OR FEATURE: need footer positioning system"
  local_vs_systemic: "LOCAL: only preventivi OR SYSTEMIC: pattern across contratti/fatture/DDT"
  symptom_vs_root_cause: "SYMPTOM: orphan text OR ROOT CAUSE: missing layout constraint system"
  implicit_requirement: "User wants professional PDF appearance (never orphan elements)"
```

**VALIDATION**:
```xml
<interpretation_check>
  <count>6</count>
  <threshold>5</threshold>
  <status>PASS</status>
  <includes_example_vs_principle>YES</includes_example_vs_principle>
</interpretation_check>
```

---

## §1.2 SEMANTIC EXPANSION (CHAIN-OF-TABLE FORMAT)
**COMMAND**: EXECUTE semantic expansion with minimum 30 terms categorized.

**CATEGORIES MANDATORY**:
1. **Business Domain** (what problem domain)
2. **Technical Domain** (what technical layer)
3. **Ecosystem Correlations** (what related entities)
4. **Abstract Concepts** (what principles/patterns)
5. **User Goals** (what user really wants)

**TABULAR FORMAT** (Chain-of-Table approach):
```
| term_id | term | category | relation_to_request | priority |
|---------|------|----------|---------------------|----------|
| T001 | disclaimer | business | legal text mentioned | HIGH |
| T002 | footer | technical | positioning mechanism | HIGH |
| T003 | page-break | technical | layout problem | HIGH |
| T004 | orphan-text | technical | specific symptom | MEDIUM |
| T005 | contratti | ecosystem | similar document type | HIGH |
| T006 | fatture | ecosystem | similar document type | HIGH |
| T007 | PDF generation | technical | artifact creation | HIGH |
| T008 | template system | technical | structure mechanism | MEDIUM |
| T009 | legal compliance | business | why text exists | MEDIUM |
| T010 | professional appearance | concepts | quality goal | HIGH |
| ... | ... | ... | ... | ... |
| T030 | multi-page layout | technical | context problem | MEDIUM |
```

**CHAIN-OF-TABLE OPERATIONS**:
```python
# Step 1: Initial expansion (30+ terms)
T0 = generate_semantic_terms(user_request)

# Step 2: Filter HIGH priority
T1 = f_filter(T0, priority="HIGH")

# Step 3: Group by category
T2 = f_group_by(T1, column="category")

# Step 4: Cross-reference (find connections)
T3 = f_add_col(T2, "connections" = count_related_terms(T2))

# Output: Terms with most connections = search priorities
```

**VALIDATION**:
```xml
<semantic_expansion_check>
  <total_terms>32</total_terms>
  <threshold>30</threshold>
  <categories_covered>5/5</categories_covered>
  <high_priority_terms>12</high_priority_terms>
  <status>PASS</status>
</semantic_expansion_check>
```

---

## §1.3 AUTO-GENERATED QUESTIONS (METACOGNITIVE PROMPTING)
**COMMAND**: ASK yourself minimum 20 questions organized by 5W1H framework.

**FRAMEWORK**:
```yaml
WHAT:
  - "What exact element is orphaned?"
  - "What would ideal layout look like?"
  - "What other documents might have same issue?"
  - "What layout constraints exist in PDF engine?"
  
WHY:
  - "Why does text move to page 2? (overflow? break-before?)"
  - "Why is this text at document end? (legal requirement? convention?)"
  - "Why wasn't this caught before? (rare edge case? recent change?)"
  
WHO:
  - "Who sees this output? (internal? client-facing? legal review?)"
  - "Who generates these PDFs? (auto? manual? batch?)"
  - "Who can be affected by fix? (other document types? users?)"
  
WHEN:
  - "When does orphan occur? (always? long documents only?)"
  - "When was this implemented? (legacy code? recent?)"
  - "When must fix be ready? (urgent? can wait?)"
  
WHERE:
  - "Where in codebase is layout logic? (component? utility? library?)"
  - "Where else is similar text rendered? (other docs?)"
  - "Where is page-break controlled? (CSS? PDF engine?)"
  
HOW:
  - "How is document currently structured? (components tree?)"
  - "How do other apps solve this? (fixed footer? keep-together?)"
  - "How to test fix won't break other cases? (short docs? multi-page?)"
```

**ADVERSARIAL QUESTIONS** (attack your assumptions):
```yaml
challenge_assumptions:
  - "Assumption: Only preventivi affected → VERIFY: checked contratti/fatture?"
  - "Assumption: Text must be at end → VERIFY: could be in header instead?"
  - "Assumption: Page 2 always empty → VERIFY: what if page 2 has other content?"
  - "Assumption: One solution fits all → VERIFY: need variants per document type?"
```

**VALIDATION**:
```xml
<questions_check>
  <total_questions>24</total_questions>
  <threshold>20</threshold>
  <covers_5W1H>YES (6/6)</covers_5W1H>
  <includes_adversarial>YES (4 challenges)</includes_adversarial>
  <status>PASS</status>
</questions_check>
```

---

## §1.4 USE CASE SCENARIOS (MINIMUM 10)
**COMMAND**: GENERATE concrete use cases including edge cases and failure modes.

**TABULAR FORMAT**:
```
| scenario_id | description | trigger | expected_behavior | edge_case_level |
|-------------|-------------|---------|-------------------|-----------------|
| UC001 | Short preventivo (0.5 pages) | content < 1 page | text stays page 1 | NORMAL |
| UC002 | Exact 1-page preventivo | content = 1 page | text at bottom page 1 | BOUNDARY |
| UC003 | Long preventivo (1.8 pages) | content > 1 page, text fits | text bottom page 2 | NORMAL |
| UC004 | ORPHAN CASE | content ≈ 1 page, text doesn't fit | text ALONE on page 2 | PROBLEM |
| UC005 | Multi-page (3+ pages) | content >> 2 pages | text on last page | NORMAL |
| UC006 | Contratto with disclaimer | similar to preventivo | same orphan risk? | ECOSYSTEM |
| UC007 | Fattura without disclaimer | different document type | no footer text | VARIATION |
| UC008 | Dynamic content length | user adds/removes items | page count varies | VARIABLE |
| UC009 | Different page sizes | A4 vs Letter | layout breaks? | INTERNATIONAL |
| UC010 | Print vs Digital view | rendering engine differs | consistent? | MEDIUM |
```

**FAILURE MODE ANALYSIS**:
```yaml
failure_scenarios:
  F001:
    trigger: "Text has 5 lines, only 3 lines space left on page 1"
    current_behavior: "Entire text block moves to page 2 (orphan)"
    root_cause: "No 'keep-together' OR 'widows/orphans' control"
    impact: "Professional appearance damaged, client questions quality"
    
  F002:
    trigger: "Developer adds more totals, pushes text over page boundary"
    current_behavior: "Orphan appears unexpectedly (regression)"
    root_cause: "No automated test for page-break behavior"
    impact: "Bug reaches production, noticed by client"
```

**VALIDATION**:
```xml
<use_cases_check>
  <total_scenarios>10</total_scenarios>
  <edge_cases>4</edge_cases>
  <failure_modes>2</failure_modes>
  <covers_ecosystem>YES (contratti, fatture mentioned)</covers_ecosystem>
  <status>PASS</status>
</use_cases_check>
```

---

## §1.5 EXPLICIT ASSUMPTIONS DECLARATION
**COMMAND**: DECLARE all assumptions with confidence scores using Confidence Chain methodology.

**FORMAT**:
```yaml
assumptions:
  A001:
    claim: "Text is legal disclaimer (not user-editable content)"
    confidence: 0.95
    basis: "Word 'disclaimer' + 'legal' in context"
    verification_needed: "Read actual text content"
    dependency: null
    
  A002:
    claim: "Orphan occurs on page 2 specifically (not page 3+)"
    confidence: 0.85
    basis: "User said 'page 2'"
    verification_needed: "Test with multi-page documents"
    dependency: null
    
  A003:
    claim: "Issue exists in both PreventivoPDF and PreventivoNoleggioPDF"
    confidence: 0.70
    basis: "Functional symmetry (§4 from rules)"
    verification_needed: "Check both file implementations"
    dependency: A001
    
  A004:
    claim: "Fix for preventivi will work for contratti"
    confidence: 0.60
    basis: "Assumption A003 + similar document structure"
    verification_needed: "Verify contratti uses same layout system"
    dependency: A003
    
  A005:
    claim: "PageShell component controls page layout"
    confidence: 0.50
    basis: "Common React pattern naming"
    verification_needed: "Grep search for PageShell"
    dependency: null

# Compound confidence calculation
compound_confidence:
  A004_chain: [A001: 0.95, A003: 0.70, A004: 0.60]
  result: 0.95 × 0.70 × 0.60 = 0.399
  verdict: "BELOW_THRESHOLD (< 0.70)"
  action: "EXPLICIT_VERIFICATION_REQUIRED before claiming contratti fix"
```

**VALIDATION**:
```xml
<assumptions_check>
  <total_assumptions>5</total_assumptions>
  <includes_confidence_scores>YES</includes_confidence_scores>
  <includes_dependency_chain>YES</includes_dependency_chain>
  <compound_confidence_calculated>YES (0.399 for A004)</compound_confidence_calculated>
  <low_confidence_flagged>YES (A004 flagged)</low_confidence_flagged>
  <status>PASS</status>
</assumptions_check>
```

---

## §1.6 AMBIGUITY IDENTIFICATION
**COMMAND**: IDENTIFY all ambiguous aspects requiring clarification.

**FORMAT**:
```yaml
ambiguities:
  AMB001:
    question: "Does 'client data text' refer to disclaimer OR customer name/address?"
    possible_interpretations:
      - "Legal disclaimer footer (more likely based on 'orphan' context)"
      - "Customer billing info header (less likely)"
    impact_if_wrong: "Would search wrong components, waste time"
    clarification_priority: MEDIUM
    
  AMB002:
    question: "Is this ONLY preventivi or all commercial documents?"
    possible_interpretations:
      - "Only preventivi (user said 'preventivi')"
      - "All docs with disclaimers (principle, not example)"
    impact_if_wrong: "Partial solution, user returns with 'also contratti'"
    clarification_priority: HIGH
    
  AMB003:
    question: "What does 'finisce' mean - ends naturally or breaks incorrectly?"
    possible_interpretations:
      - "Breaks incorrectly (orphan = problem)"
      - "Ends naturally but user wants different placement"
    impact_if_wrong: "Solution addresses wrong problem"
    clarification_priority: HIGH
```

**VALIDATION**:
```xml
<ambiguity_check>
  <total_ambiguities>3</total_ambiguities>
  <high_priority>2</high_priority>
  <includes_impact_analysis>YES</includes_impact_analysis>
  <status>PASS</status>
</ambiguity_check>
```

---

## §1.7 DOMAIN CORRELATION MAP
**COMMAND**: MAP all related domains that might be relevant.

**TABULAR FORMAT**:
```
| domain | relevance | concepts_to_explore | connection_to_request |
|--------|-----------|---------------------|----------------------|
| PDF Rendering | HIGH | page-break, widows/orphans, keep-together | Direct (layout issue) |
| Typography | MEDIUM | line-height, font-size, spacing | Indirect (affects pagination) |
| Legal/Compliance | MEDIUM | mandatory disclaimers, format requirements | Context (why text exists) |
| UX/Design | HIGH | professional appearance, consistency | Goal (user expectation) |
| Template Systems | HIGH | component structure, layout inheritance | Implementation |
| Print Standards | LOW | A4/Letter, margins, bleed | Edge case |
| Accessibility | LOW | screen readers, alt text | Not mentioned but good practice |
```

**VALIDATION**:
```xml
<domain_map_check>
  <domains_identified>7</domains_identified>
  <high_relevance_domains>3</high_relevance_domains>
  <includes_indirect_domains>YES</includes_indirect_domains>
  <status>PASS</status>
</domain_map_check>
```

---

## §1.8 THEORETICAL SOLUTION PATTERNS
**COMMAND**: THEORIZE possible solution categories WITHOUT looking at code.

**PATTERN CATALOG**:
```yaml
pattern_categories:
  structural:
    - "Footer positioning system (fixed vs inline)"
    - "Layout constraint system (keep-together rules)"
    - "Component hierarchy restructure"
    
  behavioral:
    - "Dynamic pagination logic (calculate space before render)"
    - "Content-aware flow (adjust based on remaining space)"
    
  workaround:
    - "Force page break before text (ensure space)"
    - "Reduce font size (make text fit)"
    
  architectural:
    - "Centralized disclaimer component (DRY)"
    - "Layout engine abstraction (hide complexity)"
```

**PATTERN EVALUATION** (Meta-Prompting approach):
```
| pattern | pros | cons | when_applicable |
|---------|------|------|-----------------|
| Fixed footer | Never orphans, professional | Reduces content space | Always safe |
| Keep-together | Maintains grouping | Large blocks → empty space | Variable content |
| Dynamic pagination | Optimal space usage | Complex logic, hard to maintain | Complex layouts |
| Centralized component | DRY, consistent | Initial refactor cost | Multiple docs affected |
```

**VALIDATION**:
```xml
<theory_patterns_check>
  <categories>4</categories>
  <total_patterns>9</total_patterns>
  <includes_tradeoffs>YES</includes_tradeoffs>
  <status>PASS</status>
</theory_patterns_check>
```

---

## §1.9 OUTPUT TO FILESYSTEM
**COMMAND**: WRITE complete analysis to JSON file.

**FILE STRUCTURE**:
```json
{
  "phase": 1,
  "timestamp": "2025-01-15T10:30:00Z",
  "user_request_original": "...",
  "interpretations": { ... },
  "semantic_expansion": {
    "terms": [...],
    "high_priority_search_targets": [...]
  },
  "questions": {
    "what": [...],
    "why": [...],
    "who": [...],
    "when": [...],
    "where": [...],
    "how": [...],
    "adversarial": [...]
  },
  "use_cases": [...],
  "assumptions": {
    "list": [...],
    "compound_confidence": {...}
  },
  "ambiguities": [...],
  "domain_map": [...],
  "theoretical_patterns": [...],
  "validation_summary": {
    "all_checks_passed": true,
    "total_terms": 32,
    "total_questions": 24,
    "total_scenarios": 10,
    "confidence_threshold_violations": ["A004"]
  }
}
```

**WRITE TO**: `temp_aap/[timestamp]/phase1_theory.json`

---

## §1.10 SIGNATURE VERIFICATION
**COMMAND**: GENERATE signature from phrase pool to prove phase 1 rules loaded.

**PHRASE POOL**:
```
"Expand before search after verify always"
"Question everything assume nothing verify twice"
"Theory first code second synthesis third"
"Interpret broadly verify narrowly execute precisely"
```

**ALGORITHM**:
1. Pick random word from phrase 1 (not consecutive to previous if possible)
2. Pick random word from phrase 2
3. Pick random word from phrase 3
4. Pick random word from phrase 4

**EXAMPLE OUTPUT**: `Expand[2] nothing[4] code[3] execute[7]`

**VALIDATION**:
```xml
<signature_check>
  <format>word[index] word[index] word[index] word[index]</format>
  <word_count>4</word_count>
  <from_different_phrases>YES (phrases 1,2,3,4)</from_different_phrases>
  <status>VALID</status>
</signature_check>
```

---

**END PHASE 1**

**CRITICAL**: Do NOT proceed to Phase 2 until Phase 1 JSON file is written and validated.

search[3] assume[2] first[2] precisely[4]
